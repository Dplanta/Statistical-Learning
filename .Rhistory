panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits = digits)[1]
txt <- paste0(prefix, txt)
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor)
pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor, lower.panel=panel.smooth)
lm.mod <- lm(Salary~+., data=fd_numeric)
summary(lm.mod)
par(mfrow = c(2, 2))
plot(lm.mod)
lm.log <- lm(log(Salary)~+., data=fd_numeric)
summary(lm.log)
plot(lm.log)
lm.step <- step(lm.mod)
summary(lm.step)  # model with the lowest AIC, interpretation
lm.step$coefficients
cor(fd_numeric[c("AGE", "FG_PCT", "DREB", "TOV", "BLKA", "PF",
"PTS", "OFF_RATING", "DEF_RATING", "NET_RATING", "TS_PCT", "PIE",
"MIN", "MIN_G", "WS")])
lm.step.coeff <- fd_numeric[c("AGE", "FG_PCT", "DREB", "TOV", "BLKA", "PF",
"PTS", "OFF_RATING", "DEF_RATING", "NET_RATING", "TS_PCT", "PIE",
"MIN", "MIN_G", "WS")]  # interpretation
par(mfrow = c(1,1))
corrplot(cor(lm.step.coeff), method = 'number')  # we can observe strong correlations (commentare) so...go with ridge
# Define the number of folds for cross-validation
num_folds <- 10
# Set the seed for reproducibility
set.seed(123)
# Initialize vectors to store performance metrics
mse <- numeric(num_folds)
rsquared <- numeric(num_folds)
# Perform k-fold cross-validation
for (i in 1:num_folds) {
# Create indices for train and test sets
test_indices <- ((i - 1) * nrow(fd_numeric) / num_folds + 1):(i * nrow(fd_numeric) / num_folds)
train_data <- fd_numeric[-test_indices, ]
test_data <- fd_numeric[test_indices, ]
# Fit the linear regression model on the training data
model <- lm(Salary ~ AGE + FG_PCT + DREB + TOV + BLKA + PF +
PTS + OFF_RATING + DEF_RATING + NET_RATING + TS_PCT + PIE +
MIN + MIN, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data)
# Calculate performance metrics
mse[i] <- mean((test_data$Salary - predictions)^2)
rsquared[i] <- summary(model)$r.squared
}
# Calculate average performance metrics
avg_mse <- mean(mse)
avg_rsquared <- mean(rsquared)
# Print average performance metrics
cat("Average MSE:", avg_mse, "\n")
cat("Average R-squared:", avg_rsquared, "\n")
lm.step.log <- step(lm.log)
summary(lm.step.log)
lm.step.log$coefficients
cor(fd_numeric[c("AGE", "FG_PCT", "BLK", "BLKA", "PTS",
"OFF_RATING", "DEF_RATING", "NET_RATING", "TS_PCT", "PIE", "MIN_G",
"WS")])
# Define the number of folds for cross-validation
num_folds <- 10
# Set the seed for reproducibility
set.seed(123)
# Initialize vectors to store performance metrics
mse_log <- numeric(num_folds)
rsquared_log <- numeric(num_folds)
# Perform k-fold cross-validation
for (i in 1:num_folds) {
# Create indices for train and test sets
test_indices <- ((i - 1) * nrow(fd_numeric) / num_folds + 1):(i * nrow(fd_numeric) / num_folds)
train_data <- fd_numeric[-test_indices, ]
test_data <- fd_numeric[test_indices, ]
# Fit the linear regression model on the training data
model <- lm(log(Salary) ~ AGE + FG_PCT + BLK + BLKA + PTS +
OFF_RATING + DEF_RATING + NET_RATING + TS_PCT + PIE + MIN_G +
WS, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data)
# Calculate performance metrics
mse_log[i] <- mean((test_data$Salary - 2.71^predictions)^2)
rsquared_log[i] <- summary(model)$r.squared
}
# Calculate average performance metrics
avg_mse_log <- mean(mse_log)
avg_rsquared_log <- mean(rsquared_log)
# Print average performance metrics
cat("Average MSE:", avg_mse_log, "\n")
cat("Average R-squared:", avg_rsquared_log, "\n")
pred_values <- predict(lm.step)
plot(pred_values, Salary)
res <- lm.step$residuals
largest_residuals_indices <- order(abs(res), decreasing=TRUE)
salaries <- fd_numeric[c(32,191,310,349,96,115,184,78,158,334),c("Salary","MIN_G")]
pred_values1 <- pred_values[c(32,191,310,349,96,115,184,78,158,334)]
res_values <- res[c(32,191,310,349,96,115,184,78,158,334)]
matching <- final_dataset[final_dataset$Salary %in% salaries$Salary & final_dataset$MIN_G %in% salaries$MIN_G, ]
matching_sort <- matching[order(matching$Salary),]
sal_pred_res <- cbind(salaries$Salary,pred_values1,res_values)
sal_pred_res_sort <- sal_pred_res[order(sal_pred_res[,1]),]
tab1 <- cbind(matching_sort$PLAYER_NAME,sal_pred_res_sort)
tab1
lm.mod <- lm(Salary~+., data=fd_numeric)
summary(lm.mod)
X <- model.matrix(Salary~., data=fd_numeric)
X <- X[,-1]
y <- fd_numeric$Salary
# package for ridge regression
library(glmnet)
# select n/2 observations for training set
n <- nrow(X)
n/2
set.seed(1)
train <- sample(1:n, 180)
test  <- setdiff(1:n, train)
cv.out <- cv.glmnet(X[train, ], y[train], alpha = 0, nfold=10)
plot(cv.out)
best_lambda <- cv.out$lambda.min
ridge.mod <- glmnet(X[train, ], y[train], alpha=0)
ridge.mod <- glmnet(X[train, ], y[train], alpha=0)
ridge.pred <- predict(ridge.mod, s=bestlam, newx=X[test,])
test.mse.ridge <- mean((ridge.pred-y[test])^2)
test.mse.ridge
ridge.final <- glmnet(X, y, alpha = 0)
ridge.final <- glmnet(X, y, alpha = 0)
coef(ridge.final, s=bestlam)
plot(ridge.final, xvar="lambda", label=TRUE)
#use fitted best model to make predictions
y_predicted <- predict(ridge.final, s = bestlam, newx = X)
#find SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
#find R-Squared
R2 <- 1 - sse/sst
R2
# final MSE
ridge.final.pred <- predict(ridge.final, s=bestlam, X)
test.mse.ridge <- mean((ridge.final.pred-y)^2)
test.mse.ridge
diffs <- ridge.final.pred - fd_numeric$Salary
class(diffs)
ord_indexes <- order(abs(diffs), decreasing = TRUE)
big_diffs_ind <- ord_indexes[1:10]
pred_sal_ridge <- ridge.final.pred[big_diffs_ind]
fd_ridge <- final_dataset[c(big_diffs_ind), ]
fd_ridge_cut <- fd_ridge[c('PLAYER_NAME', 'Salary')]
tab2 <- cbind(fd_ridge_cut, pred_sal_ridge, fd_ridge_cut$Salary-pred_sal_ridge)
tab2
lm.mod <- lm(Salary~+., data=fd_numeric)
summary(lm.mod)
par(mfrow = c(2, 2))
plot(lm.mod)
# Upload datasets
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
# Upload packages
library(readxl)
library(readxl)
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
# Upload datasets
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
data_traditional_per48 <- read.csv("./data/RS_traditional_per48.csv")
data_traditional_tot <- read.csv("./data/RS_traditional_TOTALS.csv")
data_advanced <- read.csv("./data/RS_advanced_per48.csv")
data_miscellaneous <- read.csv("./data/RS_miscellaneous_per48.csv")
data_vorp <- read_excel("./data/vorp.xlsx")
library(readxl)
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
library(readxl)
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
library(readxl)
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
library(readxl)
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
library(readxl)
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
# Upload datasets
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
library(readxl)
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
# Upload packages
library(readxl)
# Upload datasets
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
data_traditional_per48 <- read.csv("./data/RS_traditional_per48.csv")
data_traditional_tot <- read.csv("./data/RS_traditional_TOTALS.csv")
data_advanced <- read.csv("./data/RS_advanced_per48.csv")
data_miscellaneous <- read.csv("./data/RS_miscellaneous_per48.csv")
data_vorp <- read_excel("./data/vorp.xlsx")
# creating a new column in data_traditional_tot: MIN_G (minutes played per game)
# min/gp
MIN_G <- data_traditional_tot$MIN/data_traditional_tot$GP
data_traditional_tot <- cbind(data_traditional_tot, MIN_G)
# Select the features (columns) of interest
data_salary <- data_salary[, c(2, 3)]
data_traditional_per48 <- data_traditional_per48[, c(3, 7, 8, 15, 18, 21:32)]
data_traditional_tot <- data_traditional_tot[, c(3, 12, 68)]
data_advanced <- data_advanced[, c(3, 14, 17, 20, 23, 31, 32, 38)]
data_miscellaneous <- data_miscellaneous[, c(3, 24)]
data_vorp <- data_vorp[, c(2, 3, 23, 31, 32)]
# Rename a column to prepare the dataset to do a merge
names(data_salary)[names(data_salary) == "Player"] <- "PLAYER_NAME"
data_trad_tot <- data_traditional_tot[data_traditional_tot$MIN > 480, ]  # considering players with at least 480 minutes played along the season (better measure compared to games played)
# Merge the datasets applying a full join
data_st <- merge(data_salary, data_traditional_per48, by = "PLAYER_NAME", all = TRUE)
data_ast <- merge(data_st, data_advanced, by = "PLAYER_NAME", all = TRUE)
data_mast <- merge(data_ast, data_miscellaneous, by = "PLAYER_NAME", all = TRUE)
data_mastt <- merge(data_mast, data_trad_tot, by = "PLAYER_NAME", all = TRUE)
final_dataset <- merge(data_mastt, data_vorp, by = "PLAYER_NAME", all = TRUE)
# Facing NA values problem
# data_mast <- data_mast[!is.na(data_mast$2023/24), ]  ## not necessary, names correspond now
final_dataset <- final_dataset[!is.na(final_dataset$AGE), ]     ## NA's we need to remove because no stats on NBA.com
final_dataset <- final_dataset[!is.na(final_dataset$MIN), ]
final_dataset <- final_dataset[!is.na(final_dataset$VORP), ] ## removing NA's for MIN (players with less than 480 minutes played)
final_dataset
# Ensure that there aren't NA values
NA_number <- colSums(is.na(final_dataset))
print(NA_number)
final_dataset <- final_dataset[, -17]
colnames(final_dataset)[colnames(final_dataset) == 'PFD.y'] <- 'PFD'
colnames(final_dataset)[colnames(final_dataset) == '2023/24'] <- 'Salary'
final_dataset$Salary <- as.numeric(gsub("[\\$\\,]", "", final_dataset$Salary))
class(final_dataset$Salary)
final_dataset
View(final_dataset)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
boxplot(Salary)
attach(final_dataset)
boxplot(Salary)
summary(Salary)
hist(Salary)
# Upload packages
library(readxl)
# Upload datasets
data_salary <- read_excel("./data/NBA_players_salaries_HH.xlsx")
data_traditional_per48 <- read.csv("./data/RS_traditional_per48.csv")
data_traditional_tot <- read.csv("./data/RS_traditional_TOTALS.csv")
data_advanced <- read.csv("./data/RS_advanced_per48.csv")
data_miscellaneous <- read.csv("./data/RS_miscellaneous_per48.csv")
data_vorp <- read_excel("./data/vorp.xlsx")
# creating a new column in data_traditional_tot: MIN_G (minutes played per game)
# min/gp
MIN_G <- data_traditional_tot$MIN/data_traditional_tot$GP
data_traditional_tot <- cbind(data_traditional_tot, MIN_G)
# Select the features (columns) of interest
data_salary <- data_salary[, c(2, 3)]
data_traditional_per48 <- data_traditional_per48[, c(3, 7, 8, 15, 18, 21:32)]
data_traditional_tot <- data_traditional_tot[, c(3, 12, 68)]
data_advanced <- data_advanced[, c(3, 14, 17, 20, 23, 31, 32, 38)]
data_miscellaneous <- data_miscellaneous[, c(3, 24)]
data_vorp <- data_vorp[, c(2, 3, 23, 31, 32)]
# Rename a column to prepare the dataset to do a merge
names(data_salary)[names(data_salary) == "Player"] <- "PLAYER_NAME"
data_trad_tot <- data_traditional_tot[data_traditional_tot$MIN > 480, ]  # considering players with at least 480 minutes played along the season (better measure compared to games played)
# Merge the datasets applying a full join
data_st <- merge(data_salary, data_traditional_per48, by = "PLAYER_NAME", all = TRUE)
data_ast <- merge(data_st, data_advanced, by = "PLAYER_NAME", all = TRUE)
data_mast <- merge(data_ast, data_miscellaneous, by = "PLAYER_NAME", all = TRUE)
data_mastt <- merge(data_mast, data_trad_tot, by = "PLAYER_NAME", all = TRUE)
final_dataset <- merge(data_mastt, data_vorp, by = "PLAYER_NAME", all = TRUE)
# Facing NA values problem
# data_mast <- data_mast[!is.na(data_mast$2023/24), ]  ## not necessary, names correspond now
final_dataset <- final_dataset[!is.na(final_dataset$AGE), ]     ## NA's we need to remove because no stats on NBA.com
final_dataset <- final_dataset[!is.na(final_dataset$MIN), ]
final_dataset <- final_dataset[!is.na(final_dataset$VORP), ] ## removing NA's for MIN (players with less than 480 minutes played)
final_dataset
# Ensure that there aren't NA values
NA_number <- colSums(is.na(final_dataset))
print(NA_number)
final_dataset <- final_dataset[, -17]
colnames(final_dataset)[colnames(final_dataset) == 'PFD.y'] <- 'PFD'
colnames(final_dataset)[colnames(final_dataset) == '2023/24'] <- 'Salary'
final_dataset$Salary <- as.numeric(gsub("[\\$\\,]", "", final_dataset$Salary))
class(final_dataset$Salary)
attach(final_dataset)
numeric_cols <- sapply(final_dataset, is.numeric)
fd_numeric <- final_dataset[, numeric_cols]
summary(fd_numeric)
boxplot(Salary)
summary(Salary)
hist(Salary)
boxplot(AGE)
boxplot(GP)
boxplot(MIN)
boxplot(MIN_G, PTS)
boxplot(OREB, DREB, REB, AST)
boxplot(TOV, STL, BLK, BLKA, PF, PFD)
boxplot(FG_PCT, FG3_PCT, FT_PCT, TS_PCT)
boxplot(OFF_RATING, DEF_RATING)
boxplot(NET_RATING)
boxplot(AST_TO)
boxplot(PIE, USG_PCT)
boxplot(WS, BPM, VORP)
cov_mat <- round(cov(fd_numeric),2)
cor_mat <- round(cor(fd_numeric),2)
library(corrplot)
corrplot(cor(fd_numeric), method = 'color')
corrplot(cor(fd_numeric), method = 'ellipse')
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits = digits)[1]
txt <- paste0(prefix, txt)
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor)
pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor, lower.panel=panel.smooth)
lm.mod <- lm(Salary~+., data=fd_numeric)
summary(lm.mod)
par(mfrow = c(2, 2))
plot(lm.mod)
lm.log <- lm(log(Salary)~+., data=fd_numeric)
summary(lm.log)
plot(lm.log)
lm.step <- step(lm.mod)
summary(lm.step)  # model with the lowest AIC, interpretation
lm.step$coefficients
cor(fd_numeric[c("AGE", "FG_PCT", "DREB", "TOV", "BLKA", "PF",
"PTS", "OFF_RATING", "DEF_RATING", "NET_RATING", "TS_PCT", "PIE",
"MIN", "MIN_G", "WS")])
lm.step.coeff <- fd_numeric[c("AGE", "FG_PCT", "DREB", "TOV", "BLKA", "PF",
"PTS", "OFF_RATING", "DEF_RATING", "NET_RATING", "TS_PCT", "PIE",
"MIN", "MIN_G", "WS")]  # interpretation
par(mfrow = c(1,1))
corrplot(cor(lm.step.coeff), method = 'number')  # we can observe strong correlations (commentare) so...go with ridge
# Define the number of folds for cross-validation
num_folds <- 10
# Set the seed for reproducibility
set.seed(123)
# Initialize vectors to store performance metrics
mse <- numeric(num_folds)
rsquared <- numeric(num_folds)
# Perform k-fold cross-validation
for (i in 1:num_folds) {
# Create indices for train and test sets
test_indices <- ((i - 1) * nrow(fd_numeric) / num_folds + 1):(i * nrow(fd_numeric) / num_folds)
train_data <- fd_numeric[-test_indices, ]
test_data <- fd_numeric[test_indices, ]
# Fit the linear regression model on the training data
model <- lm(Salary ~ AGE + FG_PCT + DREB + TOV + BLKA + PF +
PTS + OFF_RATING + DEF_RATING + NET_RATING + TS_PCT + PIE +
MIN + MIN, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data)
# Calculate performance metrics
mse[i] <- mean((test_data$Salary - predictions)^2)
rsquared[i] <- summary(model)$r.squared
}
# Calculate average performance metrics
avg_mse <- mean(mse)
avg_rsquared <- mean(rsquared)
# Print average performance metrics
cat("Average MSE:", avg_mse, "\n")
cat("Average R-squared:", avg_rsquared, "\n")
lm.step.log <- step(lm.log)
summary(lm.step.log)
lm.step.log$coefficients
cor(fd_numeric[c("AGE", "FG_PCT", "BLK", "BLKA", "PTS",
"OFF_RATING", "DEF_RATING", "NET_RATING", "TS_PCT", "PIE", "MIN_G",
"WS")])
# Define the number of folds for cross-validation
num_folds <- 10
# Set the seed for reproducibility
set.seed(123)
# Initialize vectors to store performance metrics
mse_log <- numeric(num_folds)
rsquared_log <- numeric(num_folds)
# Perform k-fold cross-validation
for (i in 1:num_folds) {
# Create indices for train and test sets
test_indices <- ((i - 1) * nrow(fd_numeric) / num_folds + 1):(i * nrow(fd_numeric) / num_folds)
train_data <- fd_numeric[-test_indices, ]
test_data <- fd_numeric[test_indices, ]
# Fit the linear regression model on the training data
model <- lm(log(Salary) ~ AGE + FG_PCT + BLK + BLKA + PTS +
OFF_RATING + DEF_RATING + NET_RATING + TS_PCT + PIE + MIN_G +
WS, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data)
# Calculate performance metrics
mse_log[i] <- mean((test_data$Salary - 2.71^predictions)^2)
rsquared_log[i] <- summary(model)$r.squared
}
# Calculate average performance metrics
avg_mse_log <- mean(mse_log)
avg_rsquared_log <- mean(rsquared_log)
# Print average performance metrics
cat("Average MSE:", avg_mse_log, "\n")
cat("Average R-squared:", avg_rsquared_log, "\n")
pred_values <- predict(lm.step)
summary(Salary)
dataset$pos
final_dataset$Pos.unique
final_dataset$Pos.unique()
final_dataset$Pos
unique(final_dataset$Pos)
hist(log(Salary))
attach(final_dataset)
boxplot(Salary)
summary(Salary)
hist(Salary)
hist(log(Salary))
boxplot(AGE)
boxplot(GP)
boxplot(MIN)
boxplot(MIN_G, PTS)
boxplot(OREB, DREB, REB, AST)
boxplot(TOV, STL, BLK, BLKA, PF, PFD)
boxplot(FG_PCT, FG3_PCT, FT_PCT, TS_PCT)
boxplot(OFF_RATING, DEF_RATING)
boxplot(NET_RATING)
boxplot(AST_TO)
boxplot(PIE, USG_PCT)
boxplot(WS, BPM, VORP)
library(corrplot)
corrplot(cor(fd_numeric), method = 'color')
corrplot(cor(fd_numeric), method = 'ellipse')
# FUNCTION "pairs" for matrix plot
# define the functions "panel.hist" and "panel.cor"
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits = digits)[1]
txt <- paste0(prefix, txt)
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
# execute pairs function
pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor)
```{r correlation-independent-variables, echo=FALSE, warning=FALSE}
library(corrplot)
corrplot(cor(fd_numeric), method = 'color')
corrplot(cor(fd_numeric), method = 'ellipse')
# FUNCTION "pairs" for matrix plot
# define the functions "panel.hist" and "panel.cor"
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits = digits)[1]
txt <- paste0(prefix, txt)
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
# execute pairs function
#pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor)
#pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor, lower.panel=panel.smooth)
```{r correlation-independent-variables, warning=FALSE}
library(corrplot)
corrplot(cor(fd_numeric), method = 'color')
#corrplot(cor(fd_numeric), method = 'ellipse')
# FUNCTION "pairs" for matrix plot
# define the functions "panel.hist" and "panel.cor"
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits = digits)[1]
txt <- paste0(prefix, txt)
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
# execute pairs function
#pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor)
#pairs(fd_numeric, diag.panel=panel.hist, upper.panel=panel.cor, lower.panel=panel.smooth)
